{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "s0M-Jndak4eN"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def softmax(x: np.ndarray, axis: int = -1) -> np.ndarray:\n",
        "    x = x - np.max(x, axis=axis, keepdims=True)\n",
        "    ex = np.exp(x, dtype=np.float32)\n",
        "    return ex / np.sum(ex, axis=axis, keepdims=True, dtype=np.float32)\n",
        "\n",
        "def gelu(x: np.ndarray) -> np.ndarray:\n",
        "    return np.float32(0.5) * x * (np.float32(1.0) + np.tanh(np.sqrt(np.float32(2.0 / np.pi)) * (x + np.float32(0.044715) * (x ** 3))))\n",
        "\n",
        "\n",
        "class LayerNorm:\n",
        "    def __init__(self, d_model: int, eps: float = 1e-5):\n",
        "        if d_model <= 0:\n",
        "            raise ValueError(\"Warning: d_model must be > 0, got {d_model} instead\")\n",
        "        self.gamma = np.ones((d_model,), dtype=np.float32)\n",
        "        self.beta  = np.zeros((d_model,), dtype=np.float32)\n",
        "        self.eps = float(eps)\n",
        "\n",
        "    def __call__(self, x: np.ndarray) -> np.ndarray:\n",
        "        if x.shape[-1] != self.gamma.shape[0]:\n",
        "            raise ValueError(\n",
        "                f\"Warning: expected last dim {self.gamma.shape[0]}, got {x.shape[-1]} \"\n",
        "                f\"for input shape {x.shape}\")\n",
        "        m = np.mean(x, axis=-1, keepdims=True)\n",
        "        v = np.var(x, axis=-1, keepdims=True)\n",
        "        xhat = (x - m) / np.sqrt(v + self.eps, dtype=np.float32)\n",
        "        return self.gamma * xhat + self.beta\n",
        "\n",
        "class Linear:\n",
        "    def __init__(self, in_features: int, out_features: int, rng: np.random.Generator, std: float = 0.02):\n",
        "        if in_features <= 0 or out_features <= 0:\n",
        "            raise ValueError(\"Warning: invalid shape ({in_features}, {out_features})\")\n",
        "        W = rng.standard_normal((in_features, out_features)) * std\n",
        "        self.W = W.astype(np.float32)\n",
        "        self.b = np.zeros((out_features,), dtype=np.float32)\n",
        "\n",
        "    def __call__(self, x: np.ndarray) -> np.ndarray:\n",
        "        if x.shape[-1] != self.W.shape[0]:\n",
        "            raise ValueError(\n",
        "                f\"Warning: expected last dim {self.W.shape[0]}, got {x.shape[-1]} \"\n",
        "                f\"for input shape {x.shape}\"\n",
        "            )\n",
        "        return x @ self.W + self.b\n",
        "\n",
        "class TokenEmbedding:\n",
        "    def __init__(self, vocab_size: int, d_model: int, rng: np.random.Generator, std: float = 0.02):\n",
        "        if vocab_size <= 0 or d_model <= 0:\n",
        "            raise ValueError(f\"Warning: invalid shape ({vocab_size}, {d_model})\")\n",
        "        w = rng.standard_normal((vocab_size, d_model)) * std\n",
        "        self.weight = w.astype(np.float32)\n",
        "\n",
        "    def __call__(self, token_ids: np.ndarray) -> np.ndarray:\n",
        "        if token_ids.dtype.kind not in (\"i\", \"u\"):\n",
        "            raise TypeError(\"Warning: token_ids must be an integer array\")\n",
        "        if np.any((token_ids < 0) | (token_ids >= self.weight.shape[0])):\n",
        "            raise ValueError(\"Warning: token_id out of range\")\n",
        "        return self.weight[token_ids]\n",
        "\n",
        "def get_sinusoidal_positional_encoding(max_seq_len: int, d_model: int) -> np.ndarray:\n",
        "    if d_model % 2 != 0:\n",
        "        raise ValueError(\"Sinusoidal PE: d_model must be even\")\n",
        "    position = np.arange(max_seq_len, dtype=np.float32)[:, None]\n",
        "    div_term = np.exp(np.arange(0, d_model, 2, dtype=np.float32) * (-np.log(10000.0) / d_model))\n",
        "    pe = np.zeros((max_seq_len, d_model), dtype=np.float32)\n",
        "    pe[:, 0::2] = np.sin(position * div_term)\n",
        "    pe[:, 1::2] = np.cos(position * div_term)\n",
        "    return pe\n",
        "\n",
        "class _RopeCache:\n",
        "    def __init__(self):\n",
        "        self._cache = {}\n",
        "\n",
        "    def get(self, S: int, Dh: int, base: float) -> Tuple[np.ndarray, np.ndarray]:\n",
        "        key = (S, Dh, float(base))\n",
        "        if key in self._cache:\n",
        "            return self._cache[key]\n",
        "        if Dh % 2 != 0:\n",
        "            raise ValueError(\"Warning: head_dim must be even, got {Dh} instead\")\n",
        "        half = Dh // 2\n",
        "        idx = np.arange(half, dtype=np.float32)\n",
        "        theta = base ** (-2.0 * idx / Dh)\n",
        "        pos = np.arange(S, dtype=np.float32)\n",
        "        angles = pos[:, None] * theta[None, :]\n",
        "        cos = np.cos(angles, dtype=np.float32)[None, None, :, :]\n",
        "        sin = np.sin(angles, dtype=np.float32)[None, None, :, :]\n",
        "        self._cache[key] = (cos, sin)\n",
        "        return cos, sin\n",
        "_rope_cache = _RopeCache()\n",
        "\n",
        "def apply_rope(q: np.ndarray, k: np.ndarray, base: float = 10000.0) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    if q.shape != k.shape:\n",
        "        raise ValueError(\"Warning: q and k must share shape, got {q.shape} vs {k.shape} instead\")\n",
        "    B, H, S, Dh = q.shape\n",
        "    cos, sin = _rope_cache.get(S, Dh, base)\n",
        "    half = Dh // 2\n",
        "\n",
        "    def _rotate(x: np.ndarray) -> np.ndarray:\n",
        "        x1, x2 = x[..., :half], x[..., half:]\n",
        "        xr1 = x1 * cos - x2 * sin\n",
        "        xr2 = x1 * sin + x2 * cos\n",
        "        return np.concatenate([xr1, xr2], axis=-1)\n",
        "    return _rotate(q), _rotate(k)\n",
        "\n",
        "class ScaledDotProductAttention:\n",
        "    def __call__(self, q: np.ndarray, k: np.ndarray, v: np.ndarray,\n",
        "                 mask: Optional[np.ndarray] = None) -> Tuple[np.ndarray, np.ndarray]:\n",
        "        if not (q.shape == k.shape == v.shape):\n",
        "            raise ValueError(\"Warning: q,k,v must share shape; got {q.shape}, {k.shape}, {v.shape}\")\n",
        "        dk = q.shape[-1]\n",
        "        scores = q @ np.swapaxes(k, -2, -1) / np.sqrt(dk, dtype=np.float32)\n",
        "        if mask is not None:\n",
        "            if mask.shape != (1, 1, scores.shape[-2], scores.shape[-1]):\n",
        "                raise ValueError(\"Warning: mask shape {mask.shape} incompatible with scores {scores.shape}\")\n",
        "            scores = scores + mask\n",
        "        weights = softmax(scores, axis=-1)\n",
        "        out = weights @ v\n",
        "        return out, weights\n",
        "\n",
        "class MultiHeadAttention:\n",
        "    def __init__(self, d_model: int, n_heads: int, rng: np.random.Generator,\n",
        "                 rope: bool = False, rope_base: float = 10000.0):\n",
        "        if d_model % n_heads != 0:\n",
        "            raise ValueError(f\"Warning: d_model({d_model}) must be divisible by n_heads({n_heads}).\")\n",
        "        self.d_model = int(d_model)\n",
        "        self.n_heads = int(n_heads)\n",
        "        self.head_dim = self.d_model // self.n_heads\n",
        "        self.wq = Linear(self.d_model, self.d_model, rng)\n",
        "        self.wk = Linear(self.d_model, self.d_model, rng)\n",
        "        self.wv = Linear(self.d_model, self.d_model, rng)\n",
        "        self.wo = Linear(self.d_model, self.d_model, rng)\n",
        "        self.attn = ScaledDotProductAttention()\n",
        "        self.use_rope = bool(rope)\n",
        "        self.rope_base = float(rope_base)\n",
        "\n",
        "    def __call__(self, x: np.ndarray, mask: Optional[np.ndarray] = None,\n",
        "                 return_weights: bool = False) -> Tuple [np.ndarray, Optional[np.ndarray]]:\n",
        "        B, S, D = x.shape\n",
        "        H, Dh = self.n_heads, self.head_dim\n",
        "        def _to_heads(t: np.ndarray) -> np.ndarray:\n",
        "            th = t.reshape(B, S, H, Dh).transpose(0, 2, 1, 3)\n",
        "            return th\n",
        "\n",
        "        q = _to_heads(self.wq(x))\n",
        "        k = _to_heads(self.wk(x))\n",
        "        v = _to_heads(self.wv(x))\n",
        "\n",
        "        if self.use_rope:\n",
        "            q, k = apply_rope(q, k, base=self.rope_base)\n",
        "\n",
        "        out, weights = self.attn(q, k, v, mask=mask)\n",
        "        out = out.transpose(0, 2, 1, 3).reshape(B, S, D)\n",
        "        out = self.wo(out)\n",
        "        return (out, weights) if return_weights else (out, None)\n",
        "\n",
        "class FeedForward:\n",
        "    def __init__(self, d_model: int, d_ff: int, rng: np.random.Generator):\n",
        "        if d_ff <= 0:\n",
        "            raise ValueError(\"Warning: d_ff must be > 0, got {d_ff}\")\n",
        "        self.fc1 = Linear(d_model, d_ff, rng)\n",
        "        self.fc2 = Linear(d_ff, d_model, rng)\n",
        "\n",
        "    def __call__(self, x: np.ndarray) -> np.ndarray:\n",
        "        return self.fc2(gelu(self.fc1(x)))\n",
        "\n",
        "\n",
        "class TransformerBlock:\n",
        "    def __init__(self, d_model: int, n_heads: int, d_ff: int, rng: np.random.Generator,\n",
        "                 rope: bool = False, dropout: float = 0.0):\n",
        "        self.ln1 = LayerNorm(d_model)\n",
        "        self.mha = MultiHeadAttention(d_model, n_heads, rng, rope=rope)\n",
        "        self.ln2 = LayerNorm(d_model)\n",
        "        self.ffn = FeedForward(d_model, d_ff, rng)\n",
        "        self.dropout = float(dropout)\n",
        "        self.rng = rng\n",
        "\n",
        "    def _drop(self, x: np.ndarray) -> np.ndarray:\n",
        "        if self.dropout <= 0.0:\n",
        "            return x\n",
        "        mask = (self.rng.random(x.shape) > self.dropout).astype(np.float32)\n",
        "        return x * mask / (1.0 - self.dropout)\n",
        "\n",
        "    def __call__(self, x: np.ndarray, mask: Optional[np.ndarray] = None,\n",
        "                 return_attn: bool = False) -> Tuple [np.ndarray, Optional[np.ndarray]]:\n",
        "        h = self.ln1(x)\n",
        "        mha_out, attn_w = self.mha(h, mask=mask, return_weights=True)\n",
        "        x = x + self._drop(mha_out)\n",
        "        h2 = self.ln2(x)\n",
        "        ffn_out = self.ffn(h2)\n",
        "        x = x + self._drop(ffn_out)\n",
        "        return (x, attn_w) if return_attn else (x, None)\n",
        "\n",
        "\n",
        "class _CausalMaskCache:\n",
        "    def __init__(self):\n",
        "        self._cache = {}\n",
        "\n",
        "    def get(self, seq_len: int) -> np.ndarray:\n",
        "        if seq_len in self._cache:\n",
        "            return self._cache[seq_len]\n",
        "        mask = np.triu(np.ones((seq_len, seq_len), dtype=np.float32), k=1)\n",
        "        mask = (mask * -1e9)[None, None, :, :]\n",
        "        self._cache[seq_len] = mask\n",
        "        return mask\n",
        "\n",
        "_mask_cache = _CausalMaskCache()\n",
        "\n",
        "class GPT:\n",
        "    def __init__(self, vocab_size: int, d_model: int, n_heads: int, n_layers: int, max_seq_len: int, d_ff: Optional[int] = None, positional_encoding: str = \"sinusoidal\", rope_base: float = 10000.0, weight_tying: bool = True, dropout: float = 0.0, seed: int = 42):\n",
        "\n",
        "        self.rng = np.random.default_rng(seed)\n",
        "        self.vocab_size = int(vocab_size)\n",
        "        self.d_model = int(d_model)\n",
        "        self.n_heads = int(n_heads)\n",
        "        self.n_layers = int(n_layers)\n",
        "        self.max_seq_len = int(max_seq_len)\n",
        "        self.d_ff = int(d_ff) if d_ff is not None else 4 * self.d_model\n",
        "        self.positional_encoding = positional_encoding\n",
        "        self.rope_base = float(rope_base)\n",
        "        self.weight_tying = bool(weight_tying)\n",
        "        self.token_emb = TokenEmbedding(self.vocab_size, self.d_model, self.rng)\n",
        "\n",
        "\n",
        "        if positional_encoding == \"sinusoidal\":\n",
        "            self.pos_emb_table = get_sinusoidal_positional_encoding(\n",
        "                self.max_seq_len, self.d_model\n",
        "            ).astype(np.float32)\n",
        "        elif positional_encoding == \"learned\":\n",
        "            pe = self.rng.standard_normal((self.max_seq_len, self.d_model)) * 0.01\n",
        "            self.pos_emb_table = pe.astype(np.float32)\n",
        "        elif positional_encoding == \"rope\":\n",
        "            self.pos_emb_table = None\n",
        "        else:\n",
        "            raise ValueError(\n",
        "                \"Warning: positional_encoding must be one of {'sinusoidal','learned','rope'}.\"\n",
        "            )\n",
        "\n",
        "        self.blocks = [\n",
        "            TransformerBlock(\n",
        "                self.d_model, self.n_heads, self.d_ff, self.rng,\n",
        "                rope=(positional_encoding == \"rope\"), dropout=dropout\n",
        "            )\n",
        "            for _ in range(self.n_layers)\n",
        "        ]\n",
        "        self.ln_f = LayerNorm(self.d_model)\n",
        "\n",
        "        if not self.weight_tying:\n",
        "            W = self.rng.standard_normal((self.d_model, self.vocab_size)) * 0.02\n",
        "            self.out_W = W.astype(np.float32)\n",
        "            self.out_b = np.zeros((self.vocab_size,), dtype=np.float32)\n",
        "        else:\n",
        "            self.out_W = None\n",
        "            self.out_b = np.zeros((self.vocab_size,), dtype=np.float32)\n",
        "\n",
        "    def _embed(self, input_ids: np.ndarray) -> np.ndarray:\n",
        "        x = self.token_emb(input_ids)\n",
        "        if self.positional_encoding in (\"sinusoidal\", \"learned\"):\n",
        "            S = x.shape[1]\n",
        "            if S > self.max_seq_len:\n",
        "                raise ValueError(\"Warning: Input length {S} exceeds max_seq_len {self.max_seq_len} for absolute PEs\")\n",
        "            x = x + self.pos_emb_table[:S][None, :, :]\n",
        "        return x\n",
        "\n",
        "    @staticmethod\n",
        "    def _check_input_ids(input_ids: np.ndarray):\n",
        "        if input_ids.ndim != 2:\n",
        "            raise ValueError(\"Warning: input_ids must be [B,S], got shape {input_ids.shape}\")\n",
        "        if input_ids.dtype.kind not in (\"i\", \"u\"):\n",
        "            raise TypeError(\"Warning: input_ids must be an integer array.\")\n",
        "\n",
        "    def forward(self, input_ids: np.ndarray, return_attn: bool = False):\n",
        "        GPT._check_input_ids(input_ids)\n",
        "        B, S = input_ids.shape\n",
        "        if S > self.max_seq_len:\n",
        "            raise ValueError(\"Warning: Sequence length {S} exceeds max_seq_len {self.max_seq_len}.\")\n",
        "\n",
        "        x = self._embed(input_ids)\n",
        "        mask = _mask_cache.get(S)\n",
        "\n",
        "        last_attn = None\n",
        "        for li, block in enumerate(self.blocks):\n",
        "            if return_attn and li == (self.n_layers - 1):\n",
        "                x, last_attn = block(x, mask=mask, return_attn=True)\n",
        "            else:\n",
        "                x, _ = block(x, mask=mask, return_attn=False)\n",
        "\n",
        "        x = self.ln_f(x)\n",
        "        if self.weight_tying:\n",
        "            logits = np.einsum(\"bsd,vd -> bsv\", x, self.token_emb.weight) + self.out_b\n",
        "        else:\n",
        "            logits = x @ self.out_W + self.out_b\n",
        "\n",
        "        last_logits = logits[:, -1, :]\n",
        "        probs_next = softmax(last_logits, axis=-1)\n",
        "        return (logits, probs_next, last_attn) if return_attn else (logits, probs_next)\n"
      ],
      "metadata": {
        "id": "j3VPog6qe45T"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 360420\n",
        "model = GPT(vocab_size=64, d_model=64, n_heads=8, n_layers=2, max_seq_len=16, positional_encoding=\"sinusoidal\", weight_tying=True, seed=SEED)\n",
        "x = np.random.default_rng(SEED).integers(0, model.vocab_size, size = (1, 10), dtype = np.int32)\n",
        "_, _, attn = model.forward(x, return_attn=True)\n",
        "attn_map = attn[0, 0]\n",
        "plt.figure(figsize=(5, 4))\n",
        "im = plt.imshow(attn_map, interpolation=\"nearest\")\n",
        "plt.title(\"Attention\")\n",
        "plt.xlabel(\"Key position\")\n",
        "plt.ylabel(\"Query position\")\n",
        "plt.colorbar(im, fraction=0.046, pad=0.04)\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"attention_head0.png\", dpi=200)\n",
        "plt.show()\n",
        "print(\"Saved as attention_head0.png\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "339Ptg1bOEHn",
        "outputId": "57da120d-87fd-4948-d01e-60bdc9d3a09e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x400 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAasAAAGGCAYAAADFI66FAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAOQFJREFUeJzt3XlYVNX/B/D3MOyyiCIgiuJWouKKkpClSVIpRotaWiKVLYKA9LW0UkhTwq8SmgtqKn1LgzLXMkpJNBVzQUpL0XIjFZBfymYCzpzfH+bUyKDcgWFmLu/X89zncc49957PoPHpnHvuOQohhAAREZEJszB2AERERHfDZEVERCaPyYqIiEwekxUREZk8JisiIjJ5TFZERGTymKyIiMjkMVkREZHJY7IiIiKTx2RFZAAKhQLx8fHGDoNINpisyCQtXboUCoUC/v7+Nc79+uuviI+Px9mzZ3Vel5qaavgAAWzbto0JiaiRKLg2IJmiwMBAXLx4EWfPnsWpU6fQuXNnzbn169dj1KhR2LlzJwYPHqx1XY8ePeDq6oqsrCyDxxgZGYklS5ZA139C169fh6WlJSwtLQ0eB1FTwJ4VmZwzZ85g3759SEpKQqtWrbB27VpjhySZra0tExVRA2KyIpOzdu1auLi4YPjw4Xj66ae1klVqaipGjRoFABgyZAgUCgUUCgWysrLg7e2NX375Bbt27dKU/7vndfXqVcTExMDLyws2Njbo3LkzEhMToVarNXXOnj0LhUKB+fPnY8WKFejUqRNsbGzQv39/HDx4UFNvwoQJWLJkCQBo2lIoFJrzup5ZHTlyBI8++iicnJzg4OCAoUOHYv/+/Vp1UlNToVAosHfvXsTGxqJVq1Zo1qwZnnjiCVy+fLneP1sic8X/9SOTs3btWjz55JOwtrbGs88+i2XLluHgwYPo378/HnjgAURFRWHRokV466234OPjAwDw8fFBcnIyJk+eDAcHB7z99tsAAHd3dwDAtWvX8OCDD+LChQt45ZVX0K5dO+zbtw/Tp0/HpUuXkJycrBXDunXrUFZWhldeeQUKhQLz5s3Dk08+idOnT8PKygqvvPIKLl68iO3bt+OTTz6563f65ZdfMGjQIDg5OeGNN96AlZUVli9fjsGDB2PXrl01ns1NnjwZLi4uiIuLw9mzZ5GcnIzIyEikp6c3wE+YyAwJIhNy6NAhAUBs375dCCGEWq0Wbdu2FdHR0Zo6X3zxhQAgdu7cWeP67t27iwcffLBG+ezZs0WzZs3EyZMntcqnTZsmlEqlOH/+vBBCiDNnzggAomXLluLPP//U1Nu8ebMAILZu3aopi4iIELX9JwRAxMXFaT6HhoYKa2tr8fvvv2vKLl68KBwdHcUDDzygKVuzZo0AIIKCgoRardaUT5kyRSiVSnH16lWd7RHJHYcByaSsXbsW7u7uGDJkCICbw2ljxoxBWloaVCqV3vf94osvMGjQILi4uKC4uFhzBAUFQaVSYffu3Vr1x4wZAxcXF83nQYMGAQBOnz4tuW2VSoXvvvsOoaGh6Nixo6a8devWGDt2LPbs2YPS0lKta15++WWtYcVBgwZBpVLh3LlzktsnkgMOA5LJUKlUSEtLw5AhQ3DmzBlNub+/PxYsWIDMzEwMGzZMr3ufOnUKP//8M1q1aqXzfFFRkdbndu3aaX2+lbiuXLkiue3Lly/j2rVruPfee2uc8/HxgVqtRn5+Prp3726Q9onkgMmKTMb333+PS5cuIS0tDWlpaTXOr127Vu9kpVar8fDDD+ONN97Qef6ee+7R+qxUKnXWE430poex2ycyNUxWZDLWrl0LNzc3zSy7f9uwYQM2btyIlJQUreGx29V2rlOnTigvL0dQUFCDxXunOP6tVatWsLe3R15eXo1zJ06cgIWFBby8vBosLiI5YrIik/DXX39hw4YNGDVqFJ5++uka5z09PfHZZ59hy5YtcHZ2BnBzKvrtmjVrprN89OjRiI+Px7fffovg4GCtc1evXoWDg4Pk96KaNWumub558+a11lMqlRg2bBg2b96Ms2fPwtvbGwBQWFiIdevW4f7774eTk5OktomaGiYrMglbtmxBWVkZRo4cqfP8fffdp3lBeMWKFVAqlUhMTERJSQlsbGzw0EMPwc3NDf369cOyZcvw3nvvoXPnznBzc8NDDz2EqVOnYsuWLRgxYgQmTJiAfv36oaKiAkePHsX69etx9uxZuLq6Soq5X79+AICoqCgEBwdDqVTimWee0Vn3vffew/bt23H//fdj0qRJsLS0xPLly1FZWYl58+ZJ+2ERNUXGno5IJIQQISEhwtbWVlRUVNRaZ8KECcLKykoUFxeLlStXio4dOwqlUqk1jb2goEAMHz5cODo6CgBa09jLysrE9OnTRefOnYW1tbVwdXUVAQEBYv78+aKqqkoI8c/U9f/+97812sdt09Fv3LghJk+eLFq1aiUUCoXWNPbb6wohRE5OjggODhYODg7C3t5eDBkyROzbt0+rzq2p6wcPHtQq37lzZ63T9YmaAq4NSEREJo/vWRERkcljsiIiIpPHZEVERCaPyYqIiOps9+7dCAkJgaenJxQKBTZt2nTXa7KystC3b1/Nbgf6bJDKZEVERHVWUVGBXr166Xx5X5czZ85g+PDhGDJkCHJzcxETE4OXXnoJ3377raR2ORuQiIj0olAosHHjRoSGhtZa580338TXX3+NY8eOacqeeeYZXL16FRkZGXVuy6xfClar1bh48SIcHR3rvPQNEZGpEEKgrKwMnp6esLDQf6Dr+vXrqKqq0juG239/2tjYwMbGRu94/i07O7vGMmfBwcGIiYmRdB+zTlYXL17kmmpEZPby8/PRtm1bva69fv06OrR3QEGRflvoODg4oLy8XKssLi6uxk7X+iooKNBsgnqLu7s7SktL8ddff8HOzq5O9zHrZOXo6AgAOJfjDSeHxn389sQ9vo3aHhHJzw1UYw+2aX6X6aOqqgoFRSqcO+wNJ0dpvwdLy9Ro3+8s8vPztdanbKheVUMy62R1q+vq5GAh+S+pviwVVo3aHhHJ0N8zBhriMYaDowIOjtLuo8bfv0OdnAy2mLKHhwcKCwu1ygoLC+Hk5FTnXhVg5smKiIhuUgk1VBKny6mE2jDB/MvAgQOxbds2rbLt27dj4MCBku7DqetERDKghtDrkKq8vBy5ubnIzc0FcHNqem5uLs6fPw8AmD59OsaPH6+p/+qrr+L06dN44403cOLECSxduhSff/45pkyZIqld9qyIiGRADTWk9pOkXwEcOnQIQ4YM0XyOjY0FAISFhSE1NRWXLl3SJC4A6NChA77++mtMmTIFCxcuRNu2bfHRRx/V2FfubpisiIhkQCUEVBJfm5VaHwAGDx6MO72eq2t1isGDB+PIkSOS2/o3JisiIhnQZ1hPn2FAY+EzKyIiMnnsWRERyYAaAioZ96yYrIiIZIDDgI1gyZIl8Pb2hq2tLfz9/XHgwAFjh0REZFZuTbCQepgLoyer9PR0xMbGIi4uDjk5OejVqxeCg4NRVFRk7NCIiMyGWs/DXBg9WSUlJWHixIkIDw9Ht27dkJKSAnt7e6xevdrYoRERmQ3V38+spB7mwqjJqqqqCocPH9ZaPt7CwgJBQUHIzs42YmRERGRKjDrBori4GCqVSufy8SdOnKhRv7KyEpWVlZrPpaWlBo+RiMgcqAT0WBvQMLEYgtGHAaVISEiAs7Oz5uBeVkREN/GZlQG5urpCqVTqXD7ew8OjRv3p06ejpKREc+Tn5zdWqEREJk0NBVQSj1tbhJgDoyYra2tr9OvXD5mZmZoytVqNzMxMncvH29jYaPZdMeT+K0RE5kYt9DvMhdFfCo6NjUVYWBj8/PwwYMAAJCcno6KiAuHh4cYOjYjIbNzqLUm9xlwYPVmNGTMGly9fxsyZM1FQUIDevXsjIyOjxqQLIiJquoyerAAgMjISkZGRxg6DiMhssWdFREQmTy0UUAtpyUdqfWNisiIikgH2rIiIyOSpYAGVxAneKgPFYghMVkREMiD0GAYUHAYkIqLGJPdhQLNabomIiJom9qyIiGRAJSygEhKfWXEFCyIiakxqKKCWOFhmTtvayyJZ9drwAixsbRu30aTGbe7fOsfuN17jRGSS5P7MShbJioioqdNvGJA9KyIiakRqPbb84BYhREREDYg9KyIiGVDrsYIFJ1gQEVGj4jMrIiIyeWpYcOo6ERGZNpVQQCVxrT+p9Y2JyYqISAb0W3XdfHpWnA1IREQmjz0rIiIZUAsLqCVOsFBzggURETUmuQ8DMlkREcmAGtInTKgNE4pBMFkREcmAflPXzWfaApMVEZEM6PdSsPkkK/OJlIiImiz2rIiIZEDuq64zWRERyYDchwGZrIiIZEC/qetMVkRE1IjUQgG11KnrXBuQiIgak377WbFnRUREjUi/5ZbMJ1mZT6RERNRksWdFRCQDKiigkjgVXWp9Y2KyIiKSAbkPAzJZERHJgArSe0oqw4RiEExWREQyIPeelflESkREtbq1goXUQx9LliyBt7c3bG1t4e/vjwMHDtyxfnJyMu69917Y2dnBy8sLU6ZMwfXr1yW1yWRFRER1lp6ejtjYWMTFxSEnJwe9evVCcHAwioqKdNZft24dpk2bhri4OBw/fhyrVq1Ceno63nrrLUntMlkREcmA+HshWymH0GM2YFJSEiZOnIjw8HB069YNKSkpsLe3x+rVq3XW37dvHwIDAzF27Fh4e3tj2LBhePbZZ+/aG7sdkxURkQzUZxiwtLRU66isrNTZRlVVFQ4fPoygoCBNmYWFBYKCgpCdna3zmoCAABw+fFiTnE6fPo1t27bhsccek/T9ZDHBwjlPAaW1+bwvUF/FLw80SruuK3T/YyQi46vP2oBeXl5a5XFxcYiPj69Rv7i4GCqVCu7u7lrl7u7uOHHihM42xo4di+LiYtx///0QQuDGjRt49dVXJQ8DyiJZERE1dfVZdT0/Px9OTk6achsbmwaLKysrC3PnzsXSpUvh7++P3377DdHR0Zg9ezZmzJhR5/swWRERyUB9elZOTk5ayao2rq6uUCqVKCws1CovLCyEh4eHzmtmzJiB559/Hi+99BIAwNfXFxUVFXj55Zfx9ttvw8KibgmWz6yIiKhOrK2t0a9fP2RmZmrK1Go1MjMzMXCg7scT165dq5GQlEolAEAIUee22bMiIpIBNSwkb/mhzxYhsbGxCAsLg5+fHwYMGIDk5GRUVFQgPDwcADB+/Hi0adMGCQkJAICQkBAkJSWhT58+mmHAGTNmICQkRJO06oLJiohIBlRCAZXEYUCp9QFgzJgxuHz5MmbOnImCggL07t0bGRkZmkkX58+f1+pJvfPOO1AoFHjnnXdw4cIFtGrVCiEhIZgzZ46kdhVCSj/MxJSWlsLZ2Rm+4XOgtLY1djiyx9mARA3rhqhGFjajpKSkTs+MdLn1e/CV3U/BxsFK0rWV5dVY/sCX9Wq/sbBnRUQkA0KPtQGFGa0NyGRFRCQD3M+KiIhMnlpAj6nrBgrGAMynD0hERE2WUZNVQkIC+vfvD0dHR7i5uSE0NBR5eXnGDImIyCzd2s9K6mEujBrprl27EBERgf3792P79u2orq7GsGHDUFFRYcywiIjMjtQV128d5sKoz6wyMjK0PqempsLNzQ2HDx/GAw88YKSoiIjMT2O9Z2UsJjXBoqSkBADQokULnecrKyu1lq4vLS1tlLiIiEwdt7VvJGq1GjExMQgMDESPHj101klISICzs7PmuH1ZeyKipkoNhWYx2zofZjQMaDLJKiIiAseOHUNaWlqtdaZPn46SkhLNkZ+f34gREhGRsZjEMGBkZCS++uor7N69G23btq21no2NTYPus0JEJBdCjwkT+mxrbyxGTVZCCEyePBkbN25EVlYWOnToYMxwiIjMVn32szIHRk1WERERWLduHTZv3gxHR0cUFBQAAJydnWFnZ2fM0IiIzAonWBjQsmXLUFJSgsGDB6N169aaIz093ZhhERGZHcmTK/ToiRmT0YcBiYio/vR5yZezAYmIiBqQScwGJCKi+uEECyIiMnlMVkREZPKYrIiIyOQxWRERkckTkD67z5zmY3M2IBERmTz2rIiIZIDDgGbArlgNSyu1scOQvb9CBxitbbtNB4zWNpE5YLIiIiKTx2RFREQmj8mKiIhMnhAKCInJR2p9Y2KyIiKSAS5kS0REZGTsWRERyQCfWRERkcnjMysiIjJ57FkREZHJY8+KiIhMntCjZ2VOyYqzAYmIyOTp1bO6evUqDhw4gKKiIqjV2mvyjR8/vkECIyKiuhMAhMQ9P8xpixDJyWrr1q0YN24cysvL4eTkBIXin26kQqFgsiIiMgI1FFDwpeB/vP7663jhhRdQXl6Oq1ev4sqVK5rjzz//NESMRER0F7cmWEg9zIXkntWFCxcQFRUFe3t7Q8RDRER6UAsFFDKeui65ZxUcHIxDhw4ZIhYiItKTEPod5kJyz2r48OGYOnUqfv31V/j6+sLKykrr/MiRIxssOCIiIkCPZDVx4kQAwKxZs2qcUygUUKlU9Y+KiIgk4UvBt7l9qjoRERkfkxUREZk8TrDQYdeuXQgJCUHnzp3RuXNnjBw5Ej/88ENDx0ZERHUk9wkWkpPVp59+iqCgINjb2yMqKgpRUVGws7PD0KFDsW7dOkPESEREd3Ez+Uh9z8rYUded5GHAOXPmYN68eZgyZYqmLCoqCklJSZg9ezbGjh3boAESEdHdyf2ZleSe1enTpxESElKjfOTIkThz5kyDBEVERPRvkpOVl5cXMjMza5Tv2LEDXl5eDRIUERFJI/Q8zIXkYcDXX38dUVFRyM3NRUBAAABg7969SE1NxcKFCxs8QCIiujsOA97mtddeQ1paGo4ePYqYmBjExMTg2LFjSE9PxyuvvGKIGImI6G4asWu1ZMkSeHt7w9bWFv7+/jhw4MAd61+9ehURERFo3bo1bGxscM8992Dbtm2S2tTrPasnnngCTzzxhD6XEhGRIeiziroePav09HTExsYiJSUF/v7+SE5ORnBwMPLy8uDm5lajflVVFR5++GG4ublh/fr1aNOmDc6dO4fmzZtLapcvBRMRyYA+703pM3U9KSkJEydORHh4OAAgJSUFX3/9NVavXo1p06bVqL969Wr8+eef2Ldvn2YtWW9vb8nt1mkYsEWLFiguLgYAuLi4oEWLFrUeRERkXkpLS7WOyspKnfWqqqpw+PBhBAUFacosLCwQFBSE7Oxsndds2bIFAwcOREREBNzd3dGjRw/MnTtX8jqydepZffDBB3B0dNT8+d+7A5sC69IbsLS8YewwZE9hxDcIVUP6GqVd5c4co7RLJFV9JljcPpM7Li4O8fHxNeoXFxdDpVLB3d1dq9zd3R0nTpzQ2cbp06fx/fffY9y4cdi2bRt+++03TJo0CdXV1YiLi6tzrHVKVmFhYZo/T5gwoc43JyKiRiIU0p9B/V0/Pz8fTk5OmmIbG5sGC0utVsPNzQ0rVqyAUqlEv379cOHCBfz3v/9t+GT1b0qlEpcuXarxIO3//u//4Obmxi1CiIiMoD7PrJycnLSSVW1cXV2hVCpRWFioVV5YWAgPDw+d17Ru3RpWVlZQKpWaMh8fHxQUFKCqqgrW1tZ1ilXy1HVRy0+jsrKyzo0SEVEDa4Sp69bW1ujXr5/WwhBqtRqZmZkYOHCgzmsCAwPx22+/aW0vdfLkSbRu3VpSzqhzz2rRokUAbm6w+NFHH8HBwUFzTqVSYffu3ejatWudGyYioobTWC8Fx8bGIiwsDH5+fhgwYACSk5NRUVGhmR04fvx4tGnTBgkJCQBuvpu7ePFiREdHY/LkyTh16hTmzp2LqKgoSe3WOVl98MEHAG72rFJSUrS6dNbW1vD29kZKSoqkxomIyLyMGTMGly9fxsyZM1FQUIDevXsjIyNDM+ni/PnzsLD4Z9DOy8sL3377LaZMmYKePXuiTZs2iI6Oxptvvimp3Tonq1uL1A4ZMgQbNmyAi4uLpIaIiMjAGmnCbmRkJCIjI3Wey8rKqlE2cOBA7N+/v15tSp5gsXPnzno1SEREDU/uawPWKVnFxsZi9uzZaNasGWJjY+9YNykpqUECIyIiCfRZ68+Mll2vU7I6cuQIqqurNX+ujam9LExE1HQo/j6kXmMe6pSs/j30x2FAIiITJPOeleT3rG5XWlqKTZs21brURl29//77UCgUiImJqW9IREQkM5KT1ejRo7F48WIAwF9//QU/Pz+MHj0avr6++PLLL/UK4uDBg1i+fDl69uyp1/VERE2ezLcKlpysdu/ejUGDBgEANm7cCCEErl69ikWLFuG9996THEB5eTnGjRuHlStXcjo8EZG+bq0NKPUwE5KTVUlJiWYrkIyMDDz11FOwt7fH8OHDcerUKckBREREYPjw4VpLztemsrKyxlL2RET0z9qAUg9zITlZeXl5ITs7GxUVFcjIyMCwYcMAAFeuXIGtra2ke6WlpSEnJ0ezLMfdJCQkwNnZWXPcvqw9EVGTxWFAbTExMRg3bhzatm0LT09PDB48GMDN4UFfX9863yc/Px/R0dFYu3ZtnZPc9OnTUVJSojny8/Olhk9EJE8yHwaUvILFpEmTMGDAAOTn5+Phhx/WrAHVsWNHSc+sDh8+jKKiIvTt+8+mercWxF28eDEqKyu11h8Ebu6x0pD7rBARyYVC3DykXmMuJCcrAPDz84Ofnx+EEBBCQKFQYPjw4ZLuMXToUBw9elSrLDw8HF27dsWbb75ZI1EREVHTpdd7Vv/73//g6+sLOzs72NnZoWfPnvjkk08k3cPR0RE9evTQOpo1a4aWLVuiR48e+oRFRNR0yfyZleSeVVJSEmbMmIHIyEgEBgYCAPbs2YNXX30VxcXFmDJlSoMHSUREd1GPbe3NgeRk9eGHH2LZsmUYP368pmzkyJHo3r074uPj65WsdC0tT0REdSDz5ZYkJ6tLly4hICCgRnlAQAAuXbrUIEEREZFEMk9Wkp9Zde7cGZ9//nmN8vT0dHTp0qVBgiIiIon4zErbu+++izFjxmD37t2aZ1Z79+5FZmamziRGRERUX5KT1VNPPYUff/wRH3zwATZt2gQA8PHxwYEDB9CnT5+Gjo+IiOqCEyxq6tevHz799NOGjoWIiPTEl4J1UKlU2LhxI44fPw4A6NatGx5//HFYWup1OyIiqi+ZT7CQnF1++eUXjBw5EgUFBbj33nsBAImJiWjVqhW2bt3KF3qJiKjBSZ4N+NJLL6F79+74448/kJOTg5ycHOTn56Nnz554+eWXDREjERHdhQL/DAXW+TB20BJI7lnl5ubi0KFDWhsluri4YM6cOejfv3+DBldXlteqYWnZuGsJCoXx/poV5rQJjbm7z4i7V+//2XhtE5kYyT2re+65B4WFhTXKi4qK0Llz5wYJioiIJJL5FiGSk1VCQgKioqKwfv16/PHHH/jjjz+wfv16xMTEIDExkbv4EhEZA18K1jZixAgAwOjRo6H4eyhM/D0sFRISovmsUCigUqkaKk4iIroTzgbUtnPnTkPEQURE9cD3rG7z4IMPGiIOIiKqD/asiIjI5Mk8Wem1UzAREVFjYs+KiEgG+MyKiIhMn8xXXZc8DBgXF4dz584ZIhYiItKXzN+zkpysNm/ejE6dOmHo0KFYt24dKisrDREXERFJIHldQD2GDY1JcrLKzc3FwYMH0b17d0RHR8PDwwOvvfYaDh48aIj4iIioLtizqqlPnz5YtGgRLl68iFWrVuGPP/5AYGAgevbsiYULF6KkpKSh4yQioiasXlPXhRCorq5GVVUVhBBwcXHB4sWL4eXlhfT09IaKkYiI7kafIUC596wOHz6MyMhItG7dGlOmTEGfPn1w/Phx7Nq1C6dOncKcOXMQFRXV0LESEVFtOAyozdfXF/fddx/OnDmDVatWIT8/H++//77W9iDPPvssLl++3KCBEhHRHcg8WUl+z2r06NF44YUX0KZNm1rruLq6Qq1W1yswIiKqO7m/FCypZ1VdXY3U1FTuVUVERI1KUrKysrLC9evXDRULERGRTpKfWUVERCAxMRE3btwwRDxERKQPPrPSdvDgQWRmZuK7776Dr68vmjVrpnV+w4YNDRYcERHVjdyfWUlOVs2bN8dTTz1liFiIiKg+zCj5SCU5Wa1Zs8YQcRARUX1w88Wabty4gR07dmD58uUoKysDAFy8eBHl5eUNGhwREdWN3BeyldyzOnfuHB555BGcP38elZWVePjhh+Ho6IjExERUVlYiJSXFEHESEdGdsGelLTo6Gn5+frhy5Qrs7Ow05U888QQyMzMbNDgiIjI9S5Ysgbe3N2xtbeHv748DBw7U6bq0tDQoFAqEhoZKblNysvrhhx/wzjvvwNraWqvc29sbFy5ckBwAERHVX2MNA6anpyM2NhZxcXHIyclBr169EBwcjKKiojted/bsWfznP//BoEGD9Pp+kpOVWq2GSqWqUf7HH3/A0dFRryCIiKieGuk9q6SkJEycOBHh4eHo1q0bUlJSYG9vj9WrV9d6jUqlwrhx4/Duu++iY8eO0huFHslq2LBhSE5O1nxWKBQoLy9HXFwcHnvsMb2CICKiemqEZFVVVYXDhw8jKChIU2ZhYYGgoCBkZ2fXet2sWbPg5uaGF198UVqD/yJ5gsWCBQsQHByMbt264fr16xg7dixOnToFV1dXfPbZZ3oHQkRE+qvPS8G3r/dqY2MDGxubGvWLi4uhUqng7u6uVe7u7o4TJ07obGPPnj1YtWoVcnNzpQV3G8nJqm3btvjpp5+QlpaGn3/+GeXl5XjxxRcxbtw4rQkXjcmiUgULLv9EctO7m1GaVef+apR2qZ7qMRvQy8tLqzguLg7x8fH1DqmsrAzPP/88Vq5cCVdX13rdS3KyAgBLS0s899xz9WqYiIhMQ35+PpycnDSfdfWqgJvbPymVShQWFmqVFxYWwsPDo0b933//HWfPnkVISIim7Nb2UZaWlsjLy0OnTp3qFKPkZPW///3vjufHjx8v9ZZERFRf9ehZOTk5aSWr2lhbW6Nfv37IzMzUTD9Xq9XIzMxEZGRkjfpdu3bF0aNHtcreeecdlJWVYeHChTV6dHciOVlFR0drfa6ursa1a9dgbW0Ne3t7JisiIiNorIVsY2NjERYWBj8/PwwYMADJycmoqKhAeHg4gJsdljZt2iAhIQG2trbo0aOH1vXNmzcHgBrldyM5WV25cqVG2alTp/Daa69h6tSpUm9HREQNoZFWsBgzZgwuX76MmTNnoqCgAL1790ZGRoZm0sX58+dhYaHXSn53pBBCNMiCG4cOHcJzzz1X64wQQygtLYWzszMe6vkmLJW6x1iJSBpOsGg8N0Q1srAZJSUldRqG0+XW70GfyLlQ2thKulZVeR3HF79Vr/Ybi14TLHTeyNISFy9ebKjbERGRFDJfG1BystqyZYvWZyEELl26hMWLFyMwMLDBAiMiIrpFcrK6fQFChUKBVq1a4aGHHsKCBQsaKi4iIpKCPSttt+bIExGR6VD8fUi9xlzoPWWjuLi4xhIdRERkJI20kK2xSEpWV69eRUREBFxdXeHu7g4XFxd4eHhg+vTpuHbtml4BXLhwAc899xxatmwJOzs7+Pr64tChQ3rdi4ioqeJOwX/7888/MXDgQFy4cAHjxo2Dj48PAODXX3/Fhx9+iO3bt2PPnj34+eefsX//fkRFRd31nleuXEFgYCCGDBmCb775Bq1atcKpU6fg4uKi/zciImqK+MzqplmzZsHa2hq///57jRV3Z82ahWHDhuH555/Hd999h0WLFtXpnomJifDy8sKaNWs0ZR06dKhrSERE1ETUeRhw06ZNmD9/fo1EBQAeHh6YN28evvzyS81SHHWxZcsW+Pn5YdSoUXBzc0OfPn2wcuXKWutXVlaitLRU6yAior/J9HkVICFZXbp0Cd27d6/1fI8ePWBhYYG4uLg6N3769GksW7YMXbp0wbfffovXXnsNUVFR+Pjjj3XWT0hIgLOzs+aQsggiEZGcyf2ZVZ2TlaurK86ePVvr+TNnzsDNzU1S42q1Gn379sXcuXPRp08fvPzyy5g4cSJSUlJ01p8+fTpKSko0R35+vqT2iIhki7MBbwoODsbbb7+NqqqqGucqKysxY8YMPPLII5Iab926Nbp1095gzsfHB+fPn9dZ38bGRrOUfV2XtCciagrk3rOSNMHCz88PXbp0QUREBLp27QohBI4fP46lS5eisrLyrntd3S4wMBB5eXlaZSdPnkT79u0l3YeIqMnjbMCb2rZti+zsbEyaNAnTp0/HrcXaFQoFHn74YSxevBjt2rWT1PiUKVMQEBCAuXPnYvTo0Thw4ABWrFiBFStWSPsWRERNXGPtZ2UskpZb6tChA7755htcuXIFp06dAgB07twZLVq00Kvx/v37Y+PGjZg+fTpmzZqFDh06IDk5GePGjdPrfkREJE96bRHi4uKCAQMGNEgAI0aMwIgRIxrkXkRETRaHAYmIyOQxWRERkanjMysiIjJ97FkREZGpUwgBhZCWfaTWNya997MiIiJqLOxZERHJAYcBiYjI1HGCBRERmT72rEyfouoGFEplIzeqaNz2/s2MHopSPRjp35iy+71GaRcAVL/k3b0S6cSeFRERmT6Z96w4G5CIiEwee1ZERDLAYUAiIjJ9Mh8GZLIiIpIJc+opScVkRUQkB0JInylsRjOLmayIiGSAz6yIiMj0yfyZFaeuExGRyWPPiohIBhTqm4fUa8wFkxURkRzIfBiQyYqISAY4wYKIiEwfp64TEZGpk3vPirMBiYjI5LFnRUQkB5xgQUREpk7uw4BMVkREcsAJFkREZOrYsyIiItMn82dWnA1IREQmjz0rIiIZ4DAgERGZPrW4eUi9xkwwWRERyYHMn1kxWRERyYACegwDGiQSw+AECyIiObj1npXUQw9LliyBt7c3bG1t4e/vjwMHDtRad+XKlRg0aBBcXFzg4uKCoKCgO9avDZMVERHVWXp6OmJjYxEXF4ecnBz06tULwcHBKCoq0lk/KysLzz77LHbu3Ins7Gx4eXlh2LBhuHDhgqR2mayIiGTg1mxAqYdUSUlJmDhxIsLDw9GtWzekpKTA3t4eq1ev1ll/7dq1mDRpEnr37o2uXbvio48+glqtRmZmpqR2mayIiORA6HlIUFVVhcOHDyMoKEhTZmFhgaCgIGRnZ9fpHteuXUN1dTVatGghqW1OsCAikgGFEFBIfAZ1q35paalWuY2NDWxsbGrULy4uhkqlgru7u1a5u7s7Tpw4Uac233zzTXh6emolvLqQR7K6oQKEythREFE9Ke/tbJR2VXm/GaXdBqX++5B6DQAvLy+t4ri4OMTHxzdEVFref/99pKWlISsrC7a2tpKulUeyIiJq4urTs8rPz4eTk5OmXFevCgBcXV2hVCpRWFioVV5YWAgPD487tjV//ny8//772LFjB3r27CkpToDPrIiI5KEez6ycnJy0jtqSlbW1Nfr166c1OeLWZImBAwfWGtq8efMwe/ZsZGRkwM/PT6+vx54VERHVWWxsLMLCwuDn54cBAwYgOTkZFRUVCA8PBwCMHz8ebdq0QUJCAgAgMTERM2fOxLp16+Dt7Y2CggIAgIODAxwcHOrcLpMVEZEcNNLmi2PGjMHly5cxc+ZMFBQUoHfv3sjIyNBMujh//jwsLP4ZtFu2bBmqqqrw9NNPa91H6nMxJisiIhlozFXXIyMjERkZqfNcVlaW1uezZ8/q18htmKyIiOSA29oTEZGpU6hvHlKvMRdMVkREciDznhWnrhMRkcljz4qISA5kvvmiUXtWKpUKM2bMQIcOHWBnZ4dOnTph9uzZEGbUNSUiMgW3VrCQepgLo/asEhMTsWzZMnz88cfo3r07Dh06hPDwcDg7OyMqKsqYoRERmReZP7MyarLat28fHn/8cQwfPhwA4O3tjc8++0yvXSSJiJo0AekL2ZpPrjLuMGBAQAAyMzNx8uRJAMBPP/2EPXv24NFHH9VZv7KyEqWlpVoHERFxGNCgpk2bhtLSUnTt2hVKpRIqlQpz5szBuHHjdNZPSEjAu+++28hREhGRsRm1Z/X5559j7dq1WLduHXJycvDxxx9j/vz5+Pjjj3XWnz59OkpKSjRHfn5+I0dMRGSiBP55blXnw9hB151Re1ZTp07FtGnT8MwzzwAAfH19ce7cOSQkJCAsLKxG/dp2ryQiavI4wcJwrl27prU6LwAolUqo1Wa0BggRkSlQA1DocY2ZMGqyCgkJwZw5c9CuXTt0794dR44cQVJSEl544QVjhkVEZHbqs1OwOTBqsvrwww8xY8YMTJo0CUVFRfD09MQrr7yCmTNnGjMsIiLzw2FAw3F0dERycjKSk5ONGQYRkfmTebLiQrZERGTyuJAtEZEcyLxnxWRFRCQHnA1IRESmjrMBiYjI9HEYkIiITJ5aAAqJyUdtPsmKswGJiMjksWdFRCQHHAY0fQqVCgqhMnYYRLIgLKROKTN/ys4djNKuUFUCpxvsbnokHyYrIiJqTOxZERGRyVMLSO4pmdEECyYrIiI5EOqbh9RrzARnAxIRkcljz4qISA74zIqIiEwen1kREZHJY8+KiIhMnoAeycogkRgEkxURkRzIvGfF2YBERGTy2LMiIpIDtRqSd1NUm897VkxWRERyIPNhQCYrIiI5YLIiIiKTx/esiIjI1AmhhpC41p/U+sbEZEVEJAdCSO8pmdEwIKeuExGRyWPPiohIDoQez6zMqGfFZEVEJAdqNaCQ735WTFZERHLAnhUREZk6oVZDSOxZcTYgERE1Lpn3rDgbkIiITB57VkREcqAWgEK+PSsmKyIiORACklddN6NkxWFAIiIZEGqh16GPJUuWwNvbG7a2tvD398eBAwfuWP+LL75A165dYWtrC19fX2zbtk1ym0xWRERyINT6HRKlp6cjNjYWcXFxyMnJQa9evRAcHIyioiKd9fft24dnn30WL774Io4cOYLQ0FCEhobi2LFjktplsiIikoHG6lklJSVh4sSJCA8PR7du3ZCSkgJ7e3usXr1aZ/2FCxfikUcewdSpU+Hj44PZs2ejb9++WLx4saR2mayIiKhOqqqqcPjwYQQFBWnKLCwsEBQUhOzsbJ3XZGdna9UHgODg4Frr18asJ1iIvx8O3lBXGTkSIvkQQmHsEJqMG+pKAP/8LqvXvUSl5GG9G6gGAJSWlmqV29jYwMbGpkb94uJiqFQquLu7a5W7u7vjxIkTOtsoKCjQWb+goEBSrGadrMrKygAAWeeWGzkSIiL9lZWVwdnZWa9rra2t4eHhgT0F0ictAICDgwO8vLy0yuLi4hAfH6/X/QzFrJOVp6cn8vPz4ejoCIVC2v8NlpaWwsvLC/n5+XBycjJQhKaF35nfWa7M9TsLIVBWVgZPT0+972Fra4szZ86gqkq/ESYhRI3fn7p6VQDg6uoKpVKJwsJCrfLCwkJ4eHjovMbDw0NS/dqYdbKysLBA27Zt63UPJycns/rH3RD4nZsGfmfzoG+P6t9sbW1ha2vbANHcmbW1Nfr164fMzEyEhoYCANRqNTIzMxEZGanzmoEDByIzMxMxMTGasu3bt2PgwIGS2jbrZEVERI0rNjYWYWFh8PPzw4ABA5CcnIyKigqEh4cDAMaPH482bdogISEBABAdHY0HH3wQCxYswPDhw5GWloZDhw5hxYoVktplsiIiojobM2YMLl++jJkzZ6KgoAC9e/dGRkaGZhLF+fPnYWHxz0TzgIAArFu3Du+88w7eeustdOnSBZs2bUKPHj0ktdtkk5WNjQ3i4uJqHZuVI37npoHfmQwtMjKy1mG/rKysGmWjRo3CqFGj6tWmQjTEnEkiIiID4kvBRERk8pisiIjI5DFZERGRyWuyyUrqEvfmLCEhAf3794ejoyPc3NwQGhqKvLw8Y4fVaN5//30oFAqt9zzk6sKFC3juuefQsmVL2NnZwdfXF4cOHTJ2WAahUqkwY8YMdOjQAXZ2dujUqRNmz57dIEsXkelpkslK6hL35m7Xrl2IiIjA/v37sX37dlRXV2PYsGGoqKgwdmgGd/DgQSxfvhw9e/Y0digGd+XKFQQGBsLKygrffPMNfv31VyxYsAAuLi7GDs0gEhMTsWzZMixevBjHjx9HYmIi5s2bhw8//NDYoZEBNMnZgP7+/ujfv79miXq1Wg0vLy9MnjwZ06ZNM3J0hnf58mW4ublh165deOCBB4wdjsGUl5ejb9++WLp0Kd577z307t0bycnJxg7LYKZNm4a9e/fihx9+MHYojWLEiBFwd3fHqlWrNGVPPfUU7Ozs8OmnnxoxMjKEJtez0meJe7kpKSkBALRo0cLIkRhWREQEhg8fXmN7ArnasmUL/Pz8MGrUKLi5uaFPnz5YuXKlscMymICAAGRmZuLkyZMAgJ9++gl79uzBo48+auTIyBCa3EvB+ixxLydqtRoxMTEIDAyU/Aa5OUlLS0NOTg4OHjxo7FAazenTp7Fs2TLExsbirbfewsGDBxEVFQVra2uEhYUZO7wGN23aNJSWlqJr165QKpVQqVSYM2cOxo0bZ+zQyACaXLJq6iIiInDs2DHs2bPH2KEYTH5+PqKjo7F9+/ZGWdzTVKjVavj5+WHu3LkAgD59+uDYsWNISUmRZbL6/PPPsXbtWqxbtw7du3dHbm4uYmJi4OnpKcvv29Q1uWSlzxL3chEZGYmvvvoKu3fvrvdq9abs8OHDKCoqQt++fTVlKpUKu3fvxuLFi1FZWQmlUmnECA2jdevW6Natm1aZj48PvvzySyNFZFhTp07FtGnT8MwzzwAAfH19ce7cOSQkJDBZyVCTe2b17yXub7m1xL3UJevNhRACkZGR2LhxI77//nt06NDB2CEZ1NChQ3H06FHk5uZqDj8/P4wbNw65ubmyTFQAEBgYWOOVhJMnT6J9+/ZGisiwrl27prVgKgAolUqo1dJ2yyXz0OR6VsDdl7iXm4iICKxbtw6bN2+Go6OjZjtpZ2dn2NnZGTm6hufo6FjjeVyzZs3QsmVLWT+nmzJlCgICAjB37lyMHj0aBw4cwIoVKyRvxWAuQkJCMGfOHLRr1w7du3fHkSNHkJSUhBdeeMHYoZEhiCbqww8/FO3atRPW1tZiwIABYv/+/cYOyWAA6DzWrFlj7NAazYMPPiiio6ONHYbBbd26VfTo0UPY2NiIrl27ihUrVhg7JIMpLS0V0dHRol27dsLW1lZ07NhRvP3226KystLYoZEBNMn3rIiIyLw0uWdWRERkfpisiIjI5DFZERGRyWOyIiIik8dkRUREJo/JioiITB6TFRERmTwmKyIiMnlMVkQNzNvb+66bPMbHx6N3796NEg+RHDBZkdFMmDABoaGhWmXr16+Hra0tFixYYJygGsDBgwfx8ssvaz4rFAps2rRJq85//vMfrcWUiejOmuRCtmSaPvroI0RERCAlJcWsFxVu1arVXes4ODjAwcGhEaIhkgf2rMgkzJs3D5MnT0ZaWppWotq8eTP69u0LW1tbdOzYEe+++y5u3LgBAHjhhRcwYsQIrftUV1fDzc0Nq1at0tlOamoqmjdvjk2bNqFLly6wtbVFcHAw8vPzteotW7YMnTp1grW1Ne6991588sknmnNCCMTHx6Ndu3awsbGBp6cnoqKiNOf/PQzo7e0NAHjiiSegUCg0n28fBlSr1Zg1axbatm0LGxsb9O7dGxkZGZrzZ8+ehUKhwIYNGzBkyBDY29ujV69eyM7OrtsPmMjcGXkhXWrCwsLCxOOPPy7eeOMN4eDgIHbs2KF1fvfu3cLJyUmkpqaK33//XXz33XfC29tbxMfHCyGE2Lt3r1AqleLixYuaazZs2CCaNWsmysrKdLa5Zs0aYWVlJfz8/MS+ffvEoUOHxIABA0RAQIDWPaysrMSSJUtEXl6eWLBggVAqleL7778XQgjxxRdfCCcnJ7Ft2zZx7tw58eOPP2qtbt6+fXvxwQcfCCGEKCoq0qxwf+nSJVFUVCSEECIuLk706tVLc01SUpJwcnISn332mThx4oR44403hJWVlTh58qQQQogzZ84IAKJr167iq6++Enl5eeLpp58W7du3F9XV1Xr+DRCZDyYrMpqwsDBhbW0tAIjMzMwa54cOHSrmzp2rVfbJJ5+I1q1baz5369ZNJCYmaj6HhISICRMm1NrmmjVrBACtLWGOHz8uAIgff/xRCCFEQECAmDhxotZ1o0aNEo899pgQQogFCxaIe+65R1RVVels49/JSoibW7Rs3LhRq87tycrT01PMmTNHq07//v3FpEmThBD/JKuPPvpIc/6XX34RAMTx48dr/b5EcsFhQDKqnj17wtvbG3FxcSgvL9c699NPP2HWrFma5zsODg6YOHEiLl26hGvXrgEAXnrpJaxZswYAUFhYiG+++eaum+9ZWlqif//+ms9du3ZF8+bNcfz4cQDA8ePHERgYqHVNYGCg5vyoUaPw119/oWPHjpg4cSI2btyoGZrUR2lpKS5evHjHNm/p2bOn5s+tW7cGABQVFendNpG5YLIio2rTpg2ysrJw4cIFPPLIIygrK9OcKy8vx7vvvqu1Pf3Ro0dx6tQp2NraAgDGjx+P06dPIzs7G59++ik6dOiAQYMGGTRmLy8v5OXlYenSpbCzs8OkSZPwwAMPoLq62qDtAoCVlZXmzwqFAgC4jTs1CUxWZHTt27fHrl27UFBQoJWw+vbti7y8PHTu3LnGYWFx859uy5YtERoaijVr1iA1NbVOswhv3LiBQ4cOaT7n5eXh6tWr8PHxAQD4+Phg7969Wtfs3bsX3bp103y2s7NDSEgIFi1ahKysLGRnZ+Po0aM627OysoJKpao1HicnJ3h6et61TaKmjFPXySR4eXkhKysLQ4YMQXBwMDIyMjBz5kyMGDEC7dq1w9NPPw0LCwv89NNPOHbsGN577z3NtS+99BJGjBgBlUqFsLCwu7ZlZWWFyZMnY9GiRbC0tERkZCTuu+8+DBgwAAAwdepUjB49Gn369EFQUBC2bt2KDRs2YMeOHQBuzihUqVTw9/eHvb09Pv30U9jZ2aF9+/Y62/P29kZmZiYCAwNhY2MDFxeXGnWmTp2KuLg4dOrUCb1798aaNWuQm5uLtWvX6vPjJJId9qzIZLRt2xZZWVkoLi5GcHAwBg4ciK+++grfffcd+vfvj/vuuw8ffPBBjaQQFBSE1q1bIzg4GJ6enndtx97eHm+++SbGjh2LwMBAODg4ID09XXM+NDQUCxcuxPz589G9e3csX74ca9asweDBgwEAzZs3x8qVKxEYGIiePXtix44d2Lp1K1q2bKmzvQULFmD79u3w8vJCnz59dNaJiopCbGwsXn/9dfj6+iIjIwNbtmxBly5d6vjTI5I3hRBCGDsIovooLy9HmzZtsGbNGjz55JN3rJuamoqYmBhcvXq1cYIjogbBYUAyW2q1GsXFxViwYAGaN2+OkSNHGjskIjIQJisyW+fPn0eHDh3Qtm1bpKamwtKS/5yJ5IrDgEREZPI4wYKIiEwekxUREZk8JisiIjJ5TFZERGTymKyIiMjkMVkREZHJY7IiIiKTx2RFREQmj8mKiIhM3v8D+6tr1xWIqVgAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved as attention_head0.png\n"
          ]
        }
      ]
    }
  ]
}